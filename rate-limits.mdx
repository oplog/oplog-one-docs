---
title: 'Rate Limits'
description: 'Understanding API rate limits and how to handle rate limiting in oplog.one'
---

# Rate Limits

API calls will be rate-limited to **250 requests per minute** using a sliding window, and will be totalled per user, per application across calls to any of the oplog.one APIs.

Please give us time to process your requests. If you're sending too many requests too quickly, we'll respond with a **429 error code** (TooManyRequests).

## Rate Limit Headers

The API response headers also give you the following rate limit detailed information:

| Header              | Example | Description                                        |
| ------------------- | ------- | -------------------------------------------------- |
| `x-retry-after`     | 25      | Rate limit is exceeded. Try again in 25 seconds.  |
| `x-remaining-calls` | 0       | You have 0 remaining calls.                       |

## Rate Limit Response

When you exceed the rate limit, you'll receive a 429 status code with the following response:

```json
{
    "statusCode": 429,
    "message": "Rate limit is exceeded. Try again in 25 seconds."
}
```

## Best Practices

<CardGroup cols={2}>
  <Card title="Monitor Headers" icon="chart-line">
    Always check the `x-remaining-calls` header to monitor your usage
  </Card>
  <Card title="Implement Retry Logic" icon="arrows-rotate">
    Use the `x-retry-after` header to implement proper retry delays
  </Card>
  <Card title="Batch Requests" icon="layer-group">
    Combine multiple operations into single requests when possible
  </Card>
  <Card title="Cache Responses" icon="database">
    Cache frequently accessed data to reduce API calls
  </Card>
</CardGroup>

## Handling Rate Limits

### JavaScript Example

```javascript
async function makeAPICall(url, options = {}) {
  try {
    const response = await fetch(url, {
      ...options,
      headers: {
        'Authorization': 'Bearer YOUR_TOKEN',
        'Content-Type': 'application/json',
        ...options.headers
      }
    });

    // Check remaining calls
    const remainingCalls = response.headers.get('x-remaining-calls');
    console.log(`Remaining API calls: ${remainingCalls}`);

    if (response.status === 429) {
      const retryAfter = response.headers.get('x-retry-after');
      console.log(`Rate limited. Retry after ${retryAfter} seconds`);
      
      // Wait and retry
      await new Promise(resolve => setTimeout(resolve, retryAfter * 1000));
      return makeAPICall(url, options);
    }

    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }

    return await response.json();
  } catch (error) {
    console.error('API call failed:', error);
    throw error;
  }
}
```

### Python Example

```python
import time
import requests
from typing import Dict, Any

def make_api_call(url: str, headers: Dict = None, **kwargs) -> Dict[Any, Any]:
    """
    Make an API call with automatic rate limit handling
    """
    if headers is None:
        headers = {}
    
    headers.update({
        'Authorization': 'Bearer YOUR_TOKEN',
        'Content-Type': 'application/json'
    })
    
    try:
        response = requests.request(url=url, headers=headers, **kwargs)
        
        # Check remaining calls
        remaining_calls = response.headers.get('x-remaining-calls')
        print(f"Remaining API calls: {remaining_calls}")
        
        if response.status_code == 429:
            retry_after = int(response.headers.get('x-retry-after', 60))
            print(f"Rate limited. Retrying after {retry_after} seconds")
            
            time.sleep(retry_after)
            return make_api_call(url, headers, **kwargs)
        
        response.raise_for_status()
        return response.json()
        
    except requests.exceptions.RequestException as e:
        print(f"API call failed: {e}")
        raise
```

## Rate Limit Strategies

<AccordionGroup>
  <Accordion icon="clock" title="Request Spacing">
    **Space out your requests** to avoid hitting the limit:
    
    ```javascript
    // Space requests by 250ms to stay under 250/minute
    const RATE_LIMIT_DELAY = 250; // milliseconds
    
    async function rateLimitedRequest(url, options) {
      const result = await makeAPICall(url, options);
      await new Promise(resolve => setTimeout(resolve, RATE_LIMIT_DELAY));
      return result;
    }
    ```
  </Accordion>

  <Accordion icon="layer-group" title="Request Batching">
    **Combine multiple operations** when the API supports it:
    
    ```javascript
    // Instead of multiple single requests
    // POST /api/v1/products (single product)
    // POST /api/v1/products (single product)
    // POST /api/v1/products (single product)
    
    // Use batch operations when available
    // POST /api/v1/products/batch (multiple products)
    ```
  </Accordion>

  <Accordion icon="memory" title="Response Caching">
    **Cache responses** to reduce redundant calls:
    
    ```javascript
    const cache = new Map();
    const CACHE_TTL = 5 * 60 * 1000; // 5 minutes
    
    async function cachedAPICall(url, options) {
      const cacheKey = `${url}-${JSON.stringify(options)}`;
      const cached = cache.get(cacheKey);
      
      if (cached && Date.now() - cached.timestamp < CACHE_TTL) {
        return cached.data;
      }
      
      const data = await makeAPICall(url, options);
      cache.set(cacheKey, { data, timestamp: Date.now() });
      
      return data;
    }
    ```
  </Accordion>

  <Accordion icon="gauge-high" title="Rate Limit Monitoring">
    **Monitor your usage** to prevent hitting limits:
    
    ```javascript
    class RateLimitMonitor {
      constructor() {
        this.requestCount = 0;
        this.windowStart = Date.now();
        this.windowSize = 60 * 1000; // 1 minute
        this.maxRequests = 250;
      }
      
      canMakeRequest() {
        const now = Date.now();
        
        // Reset window if needed
        if (now - this.windowStart >= this.windowSize) {
          this.requestCount = 0;
          this.windowStart = now;
        }
        
        return this.requestCount < this.maxRequests;
      }
      
      recordRequest() {
        this.requestCount++;
      }
      
      getTimeUntilReset() {
        return this.windowSize - (Date.now() - this.windowStart);
      }
    }
    ```
  </Accordion>
</AccordionGroup>

## Common Scenarios

### High-Volume Operations

For operations that require many API calls, consider:

<Steps>
  <Step title="Plan Your Requests">
    Calculate how many API calls you'll need and plan accordingly
  </Step>
  <Step title="Implement Queuing">
    Use a queue system to manage high-volume operations
  </Step>
  <Step title="Add Progress Tracking">
    Provide feedback to users during long-running operations
  </Step>
  <Step title="Handle Failures Gracefully">
    Implement proper error handling and retry logic
  </Step>
</Steps>

### Real-time Applications

For applications requiring real-time data:

- **Use webhooks** instead of polling when available
- **Implement smart caching** with appropriate TTL values
- **Consider WebSocket connections** for real-time updates
- **Batch user actions** before sending to the API

<Warning>
**Important**: Rate limits are enforced per user, per application. If you have multiple applications or users, each will have their own rate limit allowance.
</Warning>

<Info>
**Need Higher Limits?** If your application requires higher rate limits, please contact our support team to discuss your use case and potential solutions.
</Info>